


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/phase_coupling_analysis")


import os

import matplotlib.pyplot as plt
import numpy as np
import pycircular
import seaborn as sns
import xarray as xr
from frites.conn import conn_reshape_undirected
from scipy.signal import find_peaks
from scipy.stats import circmean, circstd, circvar
from tqdm import tqdm

from src.util import _extract_roi


def circular_hist(
    ax, x, bins=16, density=True, offset=0, gaps=True, fill=False, alpha=0.3, color="b"
):
    """
    Produce a circular histogram of angles on ax.

    Parameters
    ----------
    ax : matplotlib.axes._subplots.PolarAxesSubplot
        axis instance created with subplot_kw=dict(projection='polar').

    x : array
        Angles to plot, expected in units of radians.

    bins : int, optional
        Defines the number of equal-width bins in the range. The default is 16.

    density : bool, optional
        If True plot frequency proportional to area. If False plot frequency
        proportional to radius. The default is True.

    offset : float, optional
        Sets the offset for the location of the 0 direction in units of
        radians. The default is 0.

    gaps : bool, optional
        Whether to allow gaps between bins. When gaps = False the bins are
        forced to partition the entire [-pi, pi] range. The default is True.

    Returns
    -------
    n : array or list of arrays
        The number of values in each bin.

    bins : array
        The edges of the bins.

    patches : `.BarContainer` or list of a single `.Polygon`
        Container of individual artists used to create the histogram
        or list of such containers if there are multiple input datasets.
    """
    # Wrap angles to [-pi, pi)
    x = (x + np.pi) % (2 * np.pi) - np.pi

    # Force bins to partition entire circle
    if not gaps:
        bins = np.linspace(-np.pi, np.pi, num=bins + 1)

    # Bin data and record counts
    n, bins = np.histogram(x, bins=bins)

    # Compute width of each bin
    widths = np.diff(bins)

    # By default plot frequency proportional to area
    if density:
        # Area to assign each bin
        area = n / x.size
        # Calculate corresponding bin radius
        radius = (area / np.pi) ** 0.5
    # Otherwise plot frequency proportional to radius
    else:
        radius = n

    # Plot data on ax
    patches = ax.bar(
        bins[:-1],
        radius,
        zorder=1,
        align="edge",
        width=widths,
        edgecolor="k",
        fill=fill,
        linewidth=1,
        alpha=alpha,
        color=color,
    )

    # Set the direction of the zero angle
    ax.set_theta_offset(offset)

    # Remove ylabels for area plots (they are mostly obstructive)
    if density:
        ax.set_yticks([])

    return n, bins, patches


def detect_peak_frequencies(power=None, prominence=0.01, verbose=False):

    assert power.ndim == 2
    assert isinstance(power, xr.DataArray)

    roi, freqs = power.roi.data, power.freqs.data
    n_roi = len(roi)

    rois = []
    peak_freqs = []
    peak_prominences = []

    __iter = range(n_roi)
    for i in tqdm(__iter) if verbose else __iter:
        peak_index, peak_info = find_peaks(power[i, :], prominence=prominence)
        peak_freqs += [freqs[peak_index]]
        peak_prominences += [peak_info["prominences"]]
        rois += [[roi[i]] * len(peak_index)]

    return peak_freqs, peak_prominences, rois





DATA_PATH = os.path.expanduser("~/funcog/phaseanalysis/Results/lucy/141017")

#  average_power = xr.load_dataarray(os.path.join(DATA_PATH, "average_power.nc"))
average_power = xr.load_dataarray(
    os.path.join(DATA_PATH, "average_power_whole_trial.nc")
)
power_time_series = xr.load_dataarray(
    os.path.join(DATA_PATH, "power_time_series_surr_False.nc")
)
phase_time_series = xr.load_dataarray(
    os.path.join(DATA_PATH, "phase_time_series_surr_False.nc")
)
phi_series = xr.load_dataarray(
    os.path.join(DATA_PATH, "phase_difference_time_series_surr_False.nc")
)


from src.signal.surrogates import trial_swap_surrogates

data = power_time_series.copy()  # .stack(z=("epochs", "times"))
# data = data.reset_index("z").rename({"z": "times"})
trials_surr = np.random.choice(
    range(data.sizes["trials"]),
    size=(data.sizes["trials"] // 2, power_time_series.sizes["roi"]),
    replace=True,
)
channels_surr = np.random.choice(
    range(data.sizes["roi"]),
    size=(data.sizes["trials"], power_time_series.sizes["roi"]),
)
data_surr = data.values.copy()
for c in range(data.sizes["roi"]):
    data_surr[trials_surr[:, c], c, ...] = np.flip(
        data[trials_surr[:, c], c].values, axis=-1
    )

for t in range(data.sizes["trials"]):
    data_surr[t, channels_surr[t], ...] = data_surr[t, channels_surr[t], ...]

data_surr = xr.DataArray(data_surr, dims=data.dims, coords=data.coords)

power_time_series_surr = trial_swap_surrogates(data)


n_boot = 10000
count = 0


def shuffle_along_axis(a, axis):
    idx = np.random.rand(*a.shape).argsort(axis=axis)
    return np.take_along_axis(a, idx, axis=axis)


data = power_time_series.values.copy()


trials_surr = []
while count < n_boot:
    out = np.random.choice(
        range(power_time_series.sizes["trials"]),
        size=2,
        replace=True,
    )

    if out[0] == out[1]:
        continue
    else:
        trials_surr += [out]
        count = count + 1
trials_surr = np.stack(trials_surr)

count = 0
channels_surr = []
while count < n_boot:
    out = np.random.choice(
        range(power_time_series.sizes["roi"]),
        size=2,
        replace=True,
    )

    if out[0] == out[1]:
        continue
    else:
        channels_surr += [out]
        count = count + 1
channels_surr = np.stack(channels_surr)

data_surr = []
for c_i, c_j, trial_i, trial_j in tqdm(
    np.concatenate((channels_surr, trials_surr), axis=1)
):
    x = data[trial_i, c_i]
    y = data[trial_j, c_j][..., ::-1]
    # y = shuffle_along_axis(y, axis=1)
    data_surr += [np.stack((x, y))]

data_surr = np.stack(data_surr)





bands = {"alpha": [6, 14]}


average_power_norm = average_power / average_power.max("freqs")


peak_freqs, peak_prominences, rois = detect_peak_frequencies(
    average_power_norm, prominence=0
)


plt.figure(figsize=(6, 5))
ax = plt.subplot(111)
plt.scatter(np.hstack(peak_freqs), np.hstack(peak_prominences))
plt.hlines(0.01, 0, 80, "r")
plt.ylim(-0.02, 1)
[ax.spines[key].set_visible(False) for key in ["top", "right"]]


peak_freqs, peak_prominences, rois = detect_peak_frequencies(
    average_power_norm, prominence=0.01
)


has_peak = np.zeros((average_power_norm.sizes["roi"], len(bands)), dtype=bool)

for i in tqdm(range(average_power_norm.sizes["roi"])):
    for peak in peak_freqs[i]:
        for n_band, band in enumerate(bands.keys()):
            if not has_peak[i, n_band]:
                has_peak[i, n_band] = bands[band][0] <= peak <= bands[band][1]

has_peak = xr.DataArray(
    has_peak, dims=("roi", "bands"), coords=(average_power_norm.roi, list(bands.keys()))
)

peak_freqs = xr.DataArray(
    np.hstack(peak_freqs), dims="roi", coords={"roi": np.hstack(rois)}, name="peak_freq"
)

peak_prominences = xr.DataArray(
    np.hstack(peak_prominences),
    dims="roi",
    coords={"roi": np.hstack(rois)},
    name="peak_prom",
)


rois = phi_series.roi.values
rois_s, rois_t = _extract_roi(rois, "-")

has_peaks_pairs = []

for roi_s, roi_t in zip(rois_s, rois_t):

    has_peaks_pairs += [has_peak.sel(roi=[roi_s, roi_t]).all().data]


has_peaks_pairs = xr.DataArray(has_peaks_pairs, dims=("roi"), coords={"roi": rois})


average_power = average_power.isel(roi=has_peak.isel(bands=0).values)
power_time_series = power_time_series.isel(roi=has_peak.isel(bands=0).values)
phase_time_series = phase_time_series.isel(roi=has_peak.isel(bands=0).values)
phi_series = phi_series.isel(roi=has_peaks_pairs.values)





from frites.conn.conn_utils import conn_links
from frites.utils import parallel_func


def _pec(w, x_s, x_t, kw_para):

    # define the power envelope correlations
    def pairwise_pec(w_x, w_y):
        # computes the correlation
        return w[:, w_x, :, :] * w[:, w_y, :, :]

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(pairwise_pec, **kw_para)

    # compute the single trial power envelope correlations
    return parallel(p_fun(s, t) for s, t in zip(x_s, x_t))


def _cok(w, x_s, x_t, kw_para):

    # define the power envelope correlations
    def pairwise_pec(w_x, w_y):
        # computes the correlation
        x, y = w[:, w_x, :, :], w[:, w_y, :, :]
        k_xyxy = (
            (x * y * x * y).mean(-1)
            - 2 * (x * y).mean(-1) * (x * y).mean(-1)
            - (x * x).mean(-1) * (y * y).mean(-1)
        )
        return k_xyxy / ((np.abs(x) ** 2).mean(-1) * (np.abs(y) ** 2).mean(-1))

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(pairwise_pec, **kw_para)

    # compute the single trial power envelope correlations
    return parallel(p_fun(s, t) for s, t in zip(x_s, x_t))


def power_envelope_correlations(power, n_jobs=1, verbose=False):

    # Extract dimensions
    dims = power.dims
    trials, roi, freqs = power.trials.data, power.roi.data, power.freqs.data
    ntrials, nroi, nfreqs, ntimes = power.shape

    roi_gp, roi_idx = roi, np.arange(nroi).reshape(-1, 1)
    (x_s, x_t), roi_p = conn_links(roi_gp, {})
    n_pairs = len(x_s)

    # z-score data and parse to numpy
    z_power = ((power - power.mean("times")) / power.std("times")).data

    kw_para = dict(n_jobs=n_jobs, verbose=verbose, total=n_pairs)

    pec = _pec(z_power, x_s, x_t, kw_para)
    pec = np.stack(pec, axis=1)

    # cok = _cok(z_power, x_s, x_t, kw_para)
    # cok = np.stack(cok, axis=1)

    # conversion
    pec = xr.DataArray(
        pec,
        dims=dims,
        name="pec",
        coords={"trials": trials, "roi": roi_p, "freqs": freqs},
    )
    """
    # conversion
    cok = xr.DataArray(
        cok,
        dims=dims[:-1],
        name="pec",
        coords={"trials": trials, "roi": roi_p, "freqs": freqs},
    )
    """
    return pec  # , cok


from frites.conn.conn_utils import conn_links
from frites.utils import parallel_func


def _int(w, x_s, x_t, kw_para):

    # define the power envelope correlations
    def pairwise_int(w_x, w_y):
        # computes fraciton of events above threshold that intersect
        x = w[:, w_x, :, :]
        y = w[:, w_y, :, :]
        prod = x * y
        norm = np.max([x.sum(-1), y.sum(-1)], axis=0)
        norm = np.where(norm == 0, 1, norm)
        return prod

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(pairwise_int, **kw_para)

    # compute the single trial power envelope correlations
    return parallel(p_fun(s, t) for s, t in zip(x_s, x_t))


def power_events_coincidence(power, q, n_jobs=1, verbose=False):

    # Extract dimensions
    dims = power.dims
    trials, roi, freqs = power.trials.data, power.roi.data, power.freqs.data
    ntrials, nroi, nfreqs, ntimes = power.shape

    roi_gp, roi_idx = roi, np.arange(nroi).reshape(-1, 1)
    (x_s, x_t), roi_p = conn_links(roi_gp, {})
    n_pairs = len(x_s)

    quantiles = power.quantile(q, "times")

    z_power = (power >= quantiles).values

    kw_para = dict(n_jobs=n_jobs, verbose=verbose, total=n_pairs)

    pec = _int(z_power, x_s, x_t, kw_para)
    pec = np.stack(pec, axis=1)

    # cok = _cok(z_power, x_s, x_t, kw_para)
    # cok = np.stack(cok, axis=1)
    print(pec.shape)
    # conversion
    pec = xr.DataArray(
        pec,
        dims=dims,
        name="pec",
        coords={"trials": trials, "roi": roi_p, "freqs": freqs},
    )

    return pec


quantiles = power_time_series.quantile(0.6, ("trials", "times"))
z_power = (power_time_series >= quantiles).values


z_power = xr.DataArray(
    z_power, dims=power_time_series.dims, coords=power_time_series.coords
)


x = z_power[:, 0, :, :]
y = z_power[:, 1, :, :]


pec = power_events_coincidence(
    power_time_series, 0.6
)  # power_envelope_correlations(power_time_series)
pec_surr = power_events_coincidence(
    power_time_series_surr, 0.6
)  # power_envelope_correlations(power_time_series_surr)


pec_cc = pec  # .mean("times")
pec_cc_surr = pec_surr  # .mean("times")


plt.figure(figsize=(12, 6))

roi_p = pec.roi.values

for pos, roi in enumerate(roi_p[:15]):

    ax = plt.subplot(3, 5, pos + 1)

    sns.histplot(
        pec_cc_surr.mean("times").isel(freqs=1),
        stat="probability",
        fill=False,
        color="k",
        ax=ax,
    )

    sns.histplot(
        pec_cc.sel(roi=roi).mean("times").isel(freqs=1),
        stat="probability",
        ax=ax,
        color="b",
    )

    mu = pec_cc.sel(roi=roi).isel(freqs=1).mean()
    mu_surr = pec_cc_surr.isel(freqs=1).mean()

    plt.vlines(0.2, 0, 0.2, "r", "--")

    plt.vlines(mu, 0, 0.2, "g", "--")

    [ax.spines[key].set_visible(False) for key in ["top", "right"]]

    plt.title(f"{roi} ({mu.values:.2f}; {mu_surr.values:.2f})")

plt.tight_layout()


bar = (z_power[100].sel(roi="a9/46D_9") * z_power[100].sel(roi="F6_8")).isel(freqs=1)
barx = z_power[100].sel(roi="a9/46D_9").isel(freqs=1)
bary = z_power[100].sel(roi="F6_8").isel(freqs=1)


z = (
    power_time_series[100].sel(roi="a9/46D_9") * power_time_series[100].sel(roi="F6_8")
).isel(freqs=1)
z = z >= z.quantile(0.6, "times")


bar = np.where(bar == 0, np.nan, bar)
barx = np.where(barx == 0, np.nan, barx)
bary = np.where(bary == 0, np.nan, bary)
barz = np.where(z == 0, np.nan, z)


plt.figure(figsize=(15, 4))
power_time_series[100].sel(roi="a9/46D_9").isel(freqs=1).plot()
power_time_series[100].sel(roi="F6_8").isel(freqs=1).plot()
plt.plot(power_time_series.times, bar + 8000, "k")
plt.plot(power_time_series.times, barx + 7000, "b")
plt.plot(power_time_series.times, bary + 7200, "orange")
plt.plot(power_time_series.times, barz + 8200, "red")





from xarray_einstats.stats import circmean, circstd


crackles = pec


filtered_phi_series = xr.DataArray(
    np.where(~crackles, np.nan, phi_series),
    dims=phi_series.dims,
    coords=phi_series.coords,
)


edges = phi_series.roi.data


plt.figure(figsize=(15, 10))

for pos in range(15):  # range(phi_series.sizes["roi"]):

    ax = plt.subplot(3, 5, pos + 1, projection="polar")

    out = filtered_phi_series.sel(freqs=10, roi=edges[pos]).data.flatten()
    out = out[~np.isnan(out)]

    circular_hist(
        ax,
        out,
        bins=30,
        fill=True,
    )
    m_1, m_2 = pycircular.stats.periodic_mean_std(out.data)
    # mean = mean * 180 / np.pi
    # std = std * 180 / np.pi
    plt.title(f"{edges[pos]} ({(m_2 * 180 / np.pi):.2f})")

plt.tight_layout()


out = filtered_phi_series.sel(freqs=10, roi="a7A_181-a8M_17").data.flatten()
out = out[~np.isnan(out)]
ax = plt.subplot(111, projection="polar")
circular_hist(
    ax,
    out,
    bins=30,
    fill=True,
)
m_1, m_2 = pycircular.stats.periodic_mean_std(out.data)


mu = circmean(filtered_phi_series, dims="times", nan_policy="omit")
std = circstd(filtered_phi_series, dims="times", nan_policy="omit")


plt.figure(figsize=(15, 10))

for pos in range(15):  # range(phi_series.sizes["roi"]):

    ax = plt.subplot(3, 5, pos + 1, projection="polar")

    _mu = mu.sel(freqs=10, roi=edges[pos]).data.flatten()
    _std = std.sel(freqs=10, roi=edges[pos]).data.flatten()
    # out = out[~np.isnan(out)]https://open.spotify.com/track/1Hs0FkY3V7iwOZZVg6XIv1

    circular_hist(
        ax,
        _mu,
        bins=30,
        fill=True,
    )

    circular_hist(ax, _std, bins=30, fill=True, color="g")

    m_1, m_2 = pycircular.stats.periodic_mean_std(_std.data)
    # mean = mean * 180 / np.pi
    # std = std * 180 / np.pi
    plt.title(f"{edges[pos]} ({(m_1* 180 / np.pi):.2f})")

plt.tight_layout()


std_ = circmean(std, "trials")


plt.scatter(pec_cc.mean(("trials", "times"))[:, 1], std_[:, 1] * 180 / np.pi)

plt.xlabel("Fraction of coincidence events")
plt.ylabel("Phase variance [째]")


avg_circ_mean = circmean(std, "trials") * 180 / np.pi <= 90


avg_pec = pec_cc.mean("epochs").mean("trials") >= 0.2


# plt.figure(figsize=(15, 6))
# plt.subplot(1, 2, 1)
# (pec_cc.mean("epochs").mean("trials") > 0.1).plot.imshow(cmap="binary")
# plt.subplot(1, 2, 2)
# out.plot.imshow(cmap="binary")


mask = avg_pec  # np.logical_and(avg_pec, avg_circ_mean)


A = circmean(mu, "trials")

A = xr.DataArray(np.where(~mask, np.nan, A), dims=A.dims, coords=A.coords)

A = (A + np.pi) % (2 * np.pi) - np.pi


A_w = conn_reshape_undirected(A[..., 1], fill_value=np.nan)


A_b = conn_reshape_undirected(mask[..., 1], fill_value=np.nan)


from frites.plot import plot_conn_circle, plot_conn_heatmap


def WrapToPi(x):
    xwrap = x % 2 * np.pi
    mask = np.abs(xwrap) > np.pi
    xwrap[mask] -= 2 * np.pi * np.sign(xwrap[mask])
    return xwrap


plot_conn_circle(A_b, edges_lw=4)


plot_conn_circle(
    np.abs(A_w) * 180 / np.pi,
    edges_cmap="plasma",
    edges_vmin=0,
    edges_vmax=None,
    edges_lw=5,
)


A_w_g = np.abs(A_w) * 180 / np.pi


_, _roi = _extract_roi(A_w_g.sources.data, "_")


A_w_g = (
    A_w_g.assign_coords({"sources": _roi, "targets": _roi})
    .groupby("sources")
    .mean("sources")
    .groupby("targets")
    .mean("targets")
)


plot_conn_circle(A_w_g, edges_cmap="plasma", edges_vmin=0, edges_vmax=None, edges_lw=10)


roi_s, roi_t = _extract_roi(mask.roi.data, "-")


_, roi_s_n = _extract_roi(roi_s, "_")
_, roi_t_n = _extract_roi(roi_t, "_")


mask_auto = mask * (roi_s_n != roi_t_n)[:, None]


mask_auto


A2 = xr.DataArray(np.where(~mask_auto, np.nan, A), dims=A.dims, coords=A.coords)

A2 = (A2 + np.pi) % (2 * np.pi) - np.pi


A_w2 = conn_reshape_undirected(A2[..., 1], fill_value=np.nan)
A_b2 = conn_reshape_undirected(mask_auto[..., 1], fill_value=np.nan)


plot_conn_circle(A_b2, edges_lw=4)


quantiles_l = np.arange(0, 1, 0.1)
quantiles_u = np.arange(0, 1, 0.1) + 0.1

variances = []
plt.figure(figsize=(20, 8))
pos = 0
for q_l, q_u in zip(quantiles_l, quantiles_u):

    lower_thr, upper_thr = power_time_series.quantile(
        q_l, ("trials", "times")
    ), power_time_series.quantile(q_u, ("trials", "times"))

    z_power = np.logical_and(
        power_time_series >= lower_thr, power_time_series < upper_thr
    )

    x = z_power.sel(roi="F6_8")
    y = z_power.sel(roi="F7_19")

    filtered_phi_series = xr.DataArray(
        np.where(~(x * y), np.nan, phi_series.sel(roi="F6_8-F7_19")),
        dims=phi_series.sel(roi="F6_8-F7_19").dims,
        coords=phi_series.sel(roi="F6_8-F7_19").coords,
    )

    out = filtered_phi_series.sel(freqs=10).data.flatten()
    out = out[~np.isnan(out)]

    ax = plt.subplot(2, 5, pos + 1, projection="polar")
    circular_hist(
        ax,
        out,
        bins=30,
        fill=True,
    )
    pos = pos + 1

    m_1, m_2 = pycircular.stats.periodic_mean_std(out)

    m_1 = m_1 * 180 / np.pi
    m_2 = m_2 * 180 / np.pi

    fraction = np.round((x * y).mean().values * 100, 2)
    plt.title(f"{fraction}%; mu={m_1:.2f}; sig={m_2:.2f}")

    variances += [m_2]
plt.tight_layout()


quantiles_l = np.arange(0, 1, 0.1)
quantiles_u = np.arange(0, 1, 0.1) + 0.1

variances_2 = []
plt.figure(figsize=(20, 8))
pos = 0
for q_l, q_u in zip(quantiles_l, quantiles_u):

    lower_thr, upper_thr = power_time_series.quantile(
        q_l, ("trials", "times")
    ), power_time_series.quantile(q_u, ("trials", "times"))

    z_power = np.logical_and(
        power_time_series >= lower_thr, power_time_series < upper_thr
    )

    x = z_power.sel(roi="F6_8")
    y = z_power.sel(roi="a8B_11")

    filtered_phi_series = xr.DataArray(
        np.where(~(x * y), np.nan, phi_series.sel(roi="a8B_11-F6_8")),
        dims=phi_series.sel(roi="a8B_11-F6_8").dims,
        coords=phi_series.sel(roi="a8B_11-F6_8").coords,
    )

    out = filtered_phi_series.sel(freqs=10).data.flatten()
    out = out[~np.isnan(out)]

    ax = plt.subplot(2, 5, pos + 1, projection="polar")
    circular_hist(
        ax,
        out,
        bins=30,
        fill=True,
    )
    pos = pos + 1

    m_1, m_2 = pycircular.stats.periodic_mean_std(out)

    m_1 = m_1 * 180 / np.pi
    m_2 = m_2 * 180 / np.pi

    fraction = np.round((x * y).mean().values * 100, 2)
    plt.title(f"{fraction}%; mu={m_1:.2f}; sig={m_2:.2f}")

    variances_2 += [m_2]
plt.tight_layout()


plt.plot(variances, "o", label="F6_8-F7_19")
plt.plot(variances_2, "o", label="a8B_11-F6_8")
plt.legend()
plt.ylabel("Phase std [째]")
x_ticks = [f"{q_l:.2f}-{q_u:.2f}" for q_l, q_u in zip(quantiles_l, quantiles_u)]

plt.xticks(range(len(quantiles_l)), x_ticks, rotation=45)
plt.xlabel("Interquantile ranges")


def variance_circ(edge, power_time_series, phi_series):

    quantiles_l = np.arange(0, 1, 0.1)
    quantiles_u = np.arange(0, 1, 0.1) + 0.1

    variances = np.zeros(len(quantiles_l))

    j = 0
    x_s, x_t = edge.split("-")
    for q_l, q_u in zip(quantiles_l, quantiles_u):

        lower_thr, upper_thr = power_time_series.quantile(
            q_l, ("trials", "times")
        ), power_time_series.quantile(q_u, ("trials", "times"))

        z_power = np.logical_and(
            power_time_series >= lower_thr, power_time_series < upper_thr
        )

        x = z_power.sel(roi=x_s)
        y = z_power.sel(roi=x_t)

        filtered_phi_series = xr.DataArray(
            np.where(~(x * y), np.nan, phi_series.sel(roi=edge)),
            dims=phi_series.sel(roi=edge).dims,
            coords=phi_series.sel(roi=edge).coords,
        )

        out = filtered_phi_series.data.flatten()
        out = out[~np.isnan(out)]

        m_1, m_2 = pycircular.stats.periodic_mean_std(out)

        m_1 = m_1 * 180 / np.pi
        m_2 = m_2 * 180 / np.pi

        fraction = np.round((x * y).mean().values * 100, 2)

        variances[j] = m_2
        j = j + 1
    return variances


edges = phi_series.roi.values
in1, in2 = power_time_series.sel(freqs=10), phi_series.sel(freqs=10)

kw_para = dict(n_jobs=10, verbose=True, total=len(edges))

# define the function to compute in parallel
parallel, p_fun = parallel_func(variance_circ, **kw_para)

# compute the single trial power envelope correlations
out = parallel(p_fun(edge, in1, in2) for edge in edges)


out = np.stack(out)


quantiles_l = np.arange(0, 1, 0.1)
quantiles_u = np.arange(0, 1, 0.1) + 0.1
[plt.plot(out_, "bo", lw=.1 ) for out_ in out];
plt.ylabel("Phase std [째]")
x_ticks = [f"{q_l:.2f}-{q_u:.2f}" for q_l, q_u in zip(quantiles_l, quantiles_u)]
plt.xticks(range(len(quantiles_l)), x_ticks, rotation=45)
plt.xlabel("Interquantile ranges")


idx = np.argsort(out[:, -1])
plt.imshow(out[idx], aspect="auto", cmap="turbo", vmax=200, origin="lower")
plt.colorbar(label="Phase std [째]")
plt.ylabel("#channel pair")
plt.xticks(range(len(quantiles_l)), x_ticks, rotation=45)
plt.xlabel("Interquantile ranges")
